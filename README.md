# Report Middleware

This project lives inside your existing repository. No separate repo or remote is required. All changes are committed and pushed to the `main` branch of the current repo.

## Quick Start

```powershell
# From repo root
& .\.venv\Scripts\Activate.ps1
python run_intent.py --query "revenue per customer by region last 6 months" --clarify
```

Outputs are written to:
- `last_query_results.json`
- `last_query_chart.html`

## Defining Metrics from Natural Language

```powershell
python metric_cli.py --add "gross profit / number of companies" --key gross_margin_per_company
```

## Project Structure

- `create_enhanced_dummy_db.py`: Seed local SQLite with realistic data
- `config_store/tenant1.json`: Metrics, dimensions, and settings
- `nlp/intent_parser.py`, `nlp/llm_intent_parser.py`: Intent parsing (strict mode)
- `nlp/formula_parser.py`: NL formula → SQL derived expressions
- `run_intent.py`: Main CLI; generates results and charts
- `metric_cli.py`: Add/update metrics from NL

## Git

This project is part of the existing repo. To publish updates:

```powershell
git add -A
git commit -m "Update report middleware"
git push origin main
```
# Report Middleware

Natural-language analytics to SQL with a schema-aware LLM parser, deterministic SQLAlchemy builder, interactive chart generation, and acceptance tests.

## Overview
- Flow: NL question → Intent JSON → Validation/Disambiguation → SQLAlchemy (Select + params) → SQLite execution → JSON results + Interactive charts.
- Sources of truth:
  - `config_store/tenant1.json` (semantic model: metrics, dimensions, date ranges)
  - `config_store/tenant1_db_schema.json` (database schema snapshot)
- Key guarantees: deterministic SQL generation, parameterized queries, automatic chart generation, robust tests.

## Prerequisites
- Python 3.11+ (project tested on 3.13)
- An OpenAI API key in the environment (`OPENAI_API_KEY`).

## Setup
```powershell
# From repo root
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install openai python-dotenv sqlalchemy pytest pypdf "plotly[express]" kaleido numpy pandas

# Optional: verify OpenAI key (returns model list or fails fast)
# .\.venv\Scripts\python.exe .\nlp\check_openai_key.py
```

## Configuration
- Edit `config_store/tenant1.json` to adjust metrics/dimensions/date ranges.
- The DB schema snapshot `config_store/tenant1_db_schema.json` is generated by the script below and used by the SQL builder.

## Generate/refresh DB schema snapshot
```powershell
.\.venv\Scripts\python.exe .\scripts\extract_db_schema.py
```

## Run a single question
```powershell
.\.venv\Scripts\python.exe .\run_intent.py -q "revenue from EMEA region for last 12 months"
```
- Outputs:
  - Compact and pretty intent JSON
  - Resolved dates
  - Compiled SQL (for visibility)
  - `last_query_results.json` with query results
  - `last_query_chart.html` with interactive Plotly chart (KPI/line/bar inferred from query type)

## Bulk run from test cases
```powershell
.\.venv\Scripts\python.exe .\scripts\bulk_run_intents_from_file.py -f tests\intent_test_cases.txt -o results_from_file.jsonl
```
- Produces one JSONL line per question with parse/build/execute results.
- Clarifications are flagged as `clarification_needed` and not counted as failures.

## Tests
```powershell
.\.venv\Scripts\python.exe -m pytest tests\ -v
```
- Acceptance tests in `tests/test_acceptance.py` verify:
  - Schema JSON presence and expected columns
  - Parser few-shots map to exact JSON contracts
  - Builder returns `(Select, params)` and executes
  - Trend and group_by queries return expected structure

## Key Files & Directories
- `nlp/llm_intent_parser.py` — schema-aware LLM parser with strict JSON output
- `validation/validator.py`, `validation/date_resolver.py`, `validation/disambiguator.py`
- `builder/sql_builder.py` — SQLAlchemy Core builder; prefers schema JSON for joins
- `scripts/` — bulk runner, schema extractor, SQL debug helper, examples
- `tests/` — unit + acceptance tests
- `design/DESIGN_SUMMARY.md` — architecture, components, and major issues fixed

## Troubleshooting
- If LLM returns clarifications for unsupported phrasing (e.g., specific quarters), the prompt maps common phrases to available ranges; extend `tenant1.json` or few-shot examples as needed.
- If schema differs from DB, regenerate `tenant1_db_schema.json`.
- If `OPENAI_API_KEY` is missing, set it in your environment or a `.env` file and load it in your shell.

## Quick Notes
- SQL is executed parameterized; compiled SQL is printed for debugging.
- The builder falls back to PRAGMA-based discovery only if schema JSON is absent.